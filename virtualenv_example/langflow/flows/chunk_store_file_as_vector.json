{"id":"b7dc479b-eaa0-43cf-8011-8da31ee427cd","data":{"nodes":[{"id":"Chroma-IN9jc","type":"genericNode","position":{"x":1317.6414964370545,"y":329.07241058894056},"data":{"type":"Chroma","node":{"template":{"_type":"Component","embedding":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"embedding","display_name":"Embedding","advanced":false,"input_types":["Embeddings"],"dynamic":false,"info":"","title_case":false,"type":"other"},"ingest_data":{"trace_as_input":true,"trace_as_metadata":true,"list":true,"required":false,"placeholder":"","show":true,"value":"","name":"ingest_data","display_name":"Ingest Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other"},"allow_duplicates":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"allow_duplicates","display_name":"Allow Duplicates","advanced":true,"dynamic":false,"info":"If false, will not add documents that are already in the Vector Store.","title_case":false,"type":"bool"},"chroma_server_cors_allow_origins":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"chroma_server_cors_allow_origins","display_name":"Server CORS Allow Origins","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str"},"chroma_server_grpc_port":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"chroma_server_grpc_port","display_name":"Server gRPC Port","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int"},"chroma_server_host":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"chroma_server_host","display_name":"Server Host","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str"},"chroma_server_http_port":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"chroma_server_http_port","display_name":"Server HTTP Port","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int"},"chroma_server_ssl_enabled":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"chroma_server_ssl_enabled","display_name":"Server SSL Enabled","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from copy import deepcopy\nfrom typing import TYPE_CHECKING\n\nfrom chromadb.config import Settings\nfrom langchain_chroma.vectorstores import Chroma\nfrom loguru import logger\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.base.vectorstores.utils import chroma_collection_to_data\nfrom langflow.io import BoolInput, DataInput, DropdownInput, HandleInput, IntInput, StrInput, MultilineInput\nfrom langflow.schema import Data\n\nif TYPE_CHECKING:\n    from langchain_chroma import Chroma\n\n\nclass ChromaVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    Chroma Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"Chroma DB\"\n    description: str = \"Chroma Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/chroma\"\n    name = \"Chroma\"\n    icon = \"Chroma\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            value=\"langflow\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        StrInput(\n            name=\"chroma_server_cors_allow_origins\",\n            display_name=\"Server CORS Allow Origins\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"chroma_server_host\",\n            display_name=\"Server Host\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_http_port\",\n            display_name=\"Server HTTP Port\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_grpc_port\",\n            display_name=\"Server gRPC Port\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"chroma_server_ssl_enabled\",\n            display_name=\"Server SSL Enabled\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"allow_duplicates\",\n            display_name=\"Allow Duplicates\",\n            advanced=True,\n            info=\"If false, will not add documents that are already in the Vector Store.\",\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"Similarity\", \"MMR\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=10,\n        ),\n        IntInput(\n            name=\"limit\",\n            display_name=\"Limit\",\n            advanced=True,\n            info=\"Limit the number of records to compare when Allow Duplicates is False.\",\n        ),\n    ]\n\n    def build_vector_store(self) -> Chroma:\n        \"\"\"\n        Builds the Chroma object.\n        \"\"\"\n        try:\n            from chromadb import Client\n            from langchain_chroma import Chroma\n        except ImportError:\n            raise ImportError(\n                \"Could not import Chroma integration package. \" \"Please install it with `pip install langchain-chroma`.\"\n            )\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if self.chroma_server_host:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=self.chroma_server_cors_allow_origins or [],\n                chroma_server_host=self.chroma_server_host,\n                chroma_server_http_port=self.chroma_server_http_port or None,\n                chroma_server_grpc_port=self.chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=self.chroma_server_ssl_enabled,\n            )\n            client = Client(settings=chroma_settings)\n\n        # Check persist_directory and expand it if it is a relative path\n        if self.persist_directory is not None:\n            persist_directory = self.resolve_path(self.persist_directory)\n        else:\n            persist_directory = None\n\n        chroma = Chroma(\n            persist_directory=persist_directory,\n            client=client,\n            embedding_function=self.embedding,\n            collection_name=self.collection_name,\n        )\n\n        self._add_documents_to_vector_store(chroma)\n        self.status = chroma_collection_to_data(chroma.get(limit=self.limit))\n        return chroma\n\n    def _add_documents_to_vector_store(self, vector_store: \"Chroma\") -> None:\n        \"\"\"\n        Adds documents to the Vector Store.\n        \"\"\"\n        if not self.ingest_data:\n            self.status = \"\"\n            return\n\n        _stored_documents_without_id = []\n        if self.allow_duplicates:\n            stored_data = []\n        else:\n            stored_data = chroma_collection_to_data(vector_store.get(self.limit))\n            for value in deepcopy(stored_data):\n                del value.id\n                _stored_documents_without_id.append(value)\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                if _input not in _stored_documents_without_id:\n                    documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Vector Store Inputs must be Data objects.\")\n\n        if documents and self.embedding is not None:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            vector_store.add_documents(documents)\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_name":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"pdf_chat","name":"collection_name","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str"},"limit":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"limit","display_name":"Limit","advanced":true,"dynamic":false,"info":"Limit the number of records to compare when Allow Duplicates is False.","title_case":false,"type":"int"},"number_of_results":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":10,"name":"number_of_results","display_name":"Number of Results","advanced":true,"dynamic":false,"info":"Number of results to return.","title_case":false,"type":"int"},"persist_directory":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"chroma_db","name":"persist_directory","display_name":"Persist Directory","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str"},"search_query":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"search_query","display_name":"Search Query","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"search_type":{"trace_as_metadata":true,"options":["Similarity","MMR"],"required":false,"placeholder":"","show":true,"value":"Similarity","name":"search_type","display_name":"Search Type","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str"}},"description":"Chroma Vector Store with search capabilities","icon":"Chroma","base_classes":["Data","Retriever","VectorStore"],"display_name":"Chroma DB","documentation":"https://python.langchain.com/docs/integrations/vectorstores/chroma","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Retriever"],"selected":"Retriever","name":"base_retriever","display_name":"Retriever","method":"build_base_retriever","value":"__UNDEFINED__","cache":true},{"types":["Data"],"selected":"Data","name":"search_results","display_name":"Search Results","method":"search_documents","value":"__UNDEFINED__","cache":true},{"types":["VectorStore"],"selected":"VectorStore","name":"vector_store","display_name":"Vector Store","method":"cast_vector_store","value":"__UNDEFINED__","cache":true}],"field_order":["collection_name","persist_directory","search_query","ingest_data","embedding","chroma_server_cors_allow_origins","chroma_server_host","chroma_server_http_port","chroma_server_grpc_port","chroma_server_ssl_enabled","allow_duplicates","search_type","number_of_results","limit"],"beta":false,"edited":false},"id":"Chroma-IN9jc","description":"Chroma Vector Store with search capabilities","display_name":"Chroma DB"},"selected":false,"width":384,"height":673,"positionAbsolute":{"x":1317.6414964370545,"y":329.07241058894056},"dragging":false},{"id":"OllamaEmbeddings-f3xjm","type":"genericNode","position":{"x":266.0034029922426,"y":943.4120546008456},"data":{"type":"OllamaEmbeddings","node":{"template":{"_type":"Component","base_url":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"http://localhost:11434","name":"base_url","display_name":"Ollama Base URL","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_community.embeddings import OllamaEmbeddings\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import FloatInput, MessageTextInput, Output\n\n\nclass OllamaEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Ollama Embeddings\"\n    description: str = \"Generate embeddings using Ollama models.\"\n    documentation = \"https://python.langchain.com/docs/integrations/text_embedding/ollama\"\n    icon = \"Ollama\"\n    name = \"OllamaEmbeddings\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"model\",\n            display_name=\"Ollama Model\",\n            value=\"llama2\",\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Ollama Base URL\",\n            value=\"http://localhost:11434\",\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Model Temperature\",\n            value=0.1,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            output = OllamaEmbeddings(\n                model=self.model,\n                base_url=self.base_url,\n                temperature=self.temperature,\n            )  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not connect to Ollama API.\") from e\n        return output\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"model":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"mxbai-embed-large","name":"model","display_name":"Ollama Model","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":0.1,"name":"temperature","display_name":"Model Temperature","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"float"}},"description":"Generate embeddings using Ollama models.","icon":"Ollama","base_classes":["Embeddings"],"display_name":"Ollama Embeddings","documentation":"https://python.langchain.com/docs/integrations/text_embedding/ollama","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Embeddings"],"selected":"Embeddings","name":"embeddings","display_name":"Embeddings","method":"build_embeddings","value":"__UNDEFINED__","cache":true}],"field_order":["model","base_url","temperature"],"beta":false,"edited":false},"id":"OllamaEmbeddings-f3xjm","description":"Generate embeddings using Ollama models.","display_name":"Ollama Embeddings"},"selected":false,"width":384,"height":411,"positionAbsolute":{"x":266.0034029922426,"y":943.4120546008456},"dragging":false},{"id":"File-EKi71","type":"genericNode","position":{"x":-439.0421957137347,"y":76.45526460503146},"data":{"type":"File","node":{"template":{"_type":"Component","path":{"trace_as_metadata":true,"file_path":"b7dc479b-eaa0-43cf-8011-8da31ee427cd/hackerearth.pdf","fileTypes":["txt","md","mdx","csv","json","yaml","yml","xml","html","htm","pdf","docx","py","sh","sql","js","ts","tsx"],"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"path","display_name":"Path","advanced":false,"dynamic":false,"info":"Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx","title_case":false,"type":"file"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from pathlib import Path\n\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_data\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, FileInput, Output\nfrom langflow.schema import Data\n\n\nclass FileComponent(Component):\n    display_name = \"File\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    inputs = [\n        FileInput(\n            name=\"path\",\n            display_name=\"Path\",\n            file_types=TEXT_FILE_TYPES,\n            info=f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_file\"),\n    ]\n\n    def load_file(self) -> Data:\n        if not self.path:\n            raise ValueError(\"Please, upload a file to use this component.\")\n        resolved_path = self.resolve_path(self.path)\n        silent_errors = self.silent_errors\n\n        extension = Path(resolved_path).suffix[1:].lower()\n\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n\n        data = parse_text_file_to_data(resolved_path, silent_errors)\n        self.status = data if data else \"No data\"\n        return data or Data()\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"silent_errors":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"silent_errors","display_name":"Silent Errors","advanced":true,"dynamic":false,"info":"If true, errors will not raise an exception.","title_case":false,"type":"bool"}},"description":"A generic file loader.","icon":"file-text","base_classes":["Data"],"display_name":"File","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"data","display_name":"Data","method":"load_file","value":"__UNDEFINED__","cache":true}],"field_order":["path","silent_errors"],"beta":false,"edited":false},"id":"File-EKi71","description":"A generic file loader.","display_name":"File"},"selected":false,"width":384,"height":301,"positionAbsolute":{"x":-439.0421957137347,"y":76.45526460503146},"dragging":false},{"id":"RecursiveCharacterTextSplitter-VAUSI","type":"genericNode","position":{"x":267.1184622158744,"y":-3.9933596288846047},"data":{"type":"RecursiveCharacterTextSplitter","node":{"template":{"_type":"Component","data_input":{"trace_as_input":true,"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"data_input","display_name":"Input","advanced":false,"input_types":["Document","Data"],"dynamic":false,"info":"The texts to split.","title_case":false,"type":"other"},"chunk_overlap":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"200","name":"chunk_overlap","display_name":"Chunk Overlap","advanced":false,"dynamic":false,"info":"The amount of overlap between chunks.","title_case":false,"type":"int","load_from_db":false},"chunk_size":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"2000","name":"chunk_size","display_name":"Chunk Size","advanced":false,"dynamic":false,"info":"The maximum length of each chunk.","title_case":false,"type":"int","load_from_db":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Any\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter, TextSplitter\nfrom langflow.base.textsplitters.model import LCTextSplitterComponent\nfrom langflow.inputs.inputs import DataInput, IntInput, MessageTextInput\nfrom langflow.utils.util import unescape_string\n\n\nclass RecursiveCharacterTextSplitterComponent(LCTextSplitterComponent):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text trying to keep all related text together.\"\n    documentation: str = \"https://docs.langflow.org/components/text-splitters#recursivecharactertextsplitter\"\n    name = \"RecursiveCharacterTextSplitter\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"separators\",\n            display_name=\"Separators\",\n            info='The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n            is_list=True,\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        if not self.separators:\n            separators: list[str] | None = None\n        else:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            separators = [unescape_string(x) for x in self.separators]\n\n        return RecursiveCharacterTextSplitter(\n            separators=separators,\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"separators":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":true,"required":false,"placeholder":"","show":true,"value":["."],"name":"separators","display_name":"Separators","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The characters to split on.\nIf left empty defaults to [\"\\n\\n\", \"\\n\", \" \", \"\"].","title_case":false,"type":"str"}},"description":"Split text trying to keep all related text together.","base_classes":["Data"],"display_name":"Recursive Character Text Splitter","documentation":"https://docs.langflow.org/components/text-splitters#recursivecharactertextsplitter","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"data","display_name":"Data","method":"split_data","value":"__UNDEFINED__","cache":true}],"field_order":["chunk_size","chunk_overlap","data_input","separators"],"beta":false,"edited":false},"id":"RecursiveCharacterTextSplitter-VAUSI","description":"Split text trying to keep all related text together.","display_name":"Recursive Character Text Splitter"},"selected":false,"width":384,"height":557,"positionAbsolute":{"x":267.1184622158744,"y":-3.9933596288846047},"dragging":false}],"edges":[{"source":"OllamaEmbeddings-f3xjm","sourceHandle":"{œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-f3xjmœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}","target":"Chroma-IN9jc","targetHandle":"{œfieldNameœ:œembeddingœ,œidœ:œChroma-IN9jcœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"embedding","id":"Chroma-IN9jc","inputTypes":["Embeddings"],"type":"other"},"sourceHandle":{"dataType":"OllamaEmbeddings","id":"OllamaEmbeddings-f3xjm","name":"embeddings","output_types":["Embeddings"]}},"id":"reactflow__edge-OllamaEmbeddings-f3xjm{œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-f3xjmœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-Chroma-IN9jc{œfieldNameœ:œembeddingœ,œidœ:œChroma-IN9jcœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}","className":""},{"source":"File-EKi71","sourceHandle":"{œdataTypeœ:œFileœ,œidœ:œFile-EKi71œ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}","target":"RecursiveCharacterTextSplitter-VAUSI","targetHandle":"{œfieldNameœ:œdata_inputœ,œidœ:œRecursiveCharacterTextSplitter-VAUSIœ,œinputTypesœ:[œDocumentœ,œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data_input","id":"RecursiveCharacterTextSplitter-VAUSI","inputTypes":["Document","Data"],"type":"other"},"sourceHandle":{"dataType":"File","id":"File-EKi71","name":"data","output_types":["Data"]}},"id":"reactflow__edge-File-EKi71{œdataTypeœ:œFileœ,œidœ:œFile-EKi71œ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-RecursiveCharacterTextSplitter-VAUSI{œfieldNameœ:œdata_inputœ,œidœ:œRecursiveCharacterTextSplitter-VAUSIœ,œinputTypesœ:[œDocumentœ,œDataœ],œtypeœ:œotherœ}","className":""},{"source":"RecursiveCharacterTextSplitter-VAUSI","sourceHandle":"{œdataTypeœ:œRecursiveCharacterTextSplitterœ,œidœ:œRecursiveCharacterTextSplitter-VAUSIœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}","target":"Chroma-IN9jc","targetHandle":"{œfieldNameœ:œingest_dataœ,œidœ:œChroma-IN9jcœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"ingest_data","id":"Chroma-IN9jc","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"RecursiveCharacterTextSplitter","id":"RecursiveCharacterTextSplitter-VAUSI","name":"data","output_types":["Data"]}},"id":"reactflow__edge-RecursiveCharacterTextSplitter-VAUSI{œdataTypeœ:œRecursiveCharacterTextSplitterœ,œidœ:œRecursiveCharacterTextSplitter-VAUSIœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-Chroma-IN9jc{œfieldNameœ:œingest_dataœ,œidœ:œChroma-IN9jcœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","className":""}],"viewport":{"x":496.1341217682889,"y":130.95594999870588,"zoom":0.39534898773673466}},"description":"Split the contents of a file and store chunks in a vector store. ","name":"chunk-store-file-as-vector","last_tested_version":"1.0.9","endpoint_name":null,"is_component":false}